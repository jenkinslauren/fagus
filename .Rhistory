'/clipped_data/envDataClipped_', climYear, 'YBP_pc', pc, '.tif')
vars <- names(clim[[1]])
# set constants for Lorenz gcm's
if (gcm == 'ccsm' | gcm == 'ecbilt') {
clim <- lorenz
workingFolder <- paste0('/Volumes/lj_mac_22/MOBOT/by_genus/env_data/', gcm,
'/tifs/', climYear, 'BP')
vars <- names(clim[[1]])
}
## load environment data from PCA ##
if (file.exists(fileName)) {  # if already clipped to respective year, load that
envData <- brick(fileName)
names(envData) <- paste0('pca', 1:pc) # rename raster layers to match pc
} else { # otherwise, clip data to correct climate year
pcPrediction <- list()
for (i in 1:length(clim)) { # label each env layer by variable name and year
names(clim[[i]]) <- vars
pcPrediction[i] <- raster::predict(clim[[i]], pca, index = 1:pc)
names(pcPrediction[[i]]) <- paste0("pc", 1:pc, "_", (i-1)*1000, "KYBP")
}
envDataPca <- stack(pcPrediction)
envYr <- pcPrediction[[(climYear/1000) + 1]] # keep only the PCA rasters for given climate year
names(envYr) <- paste0('pca', 1:pc) # label layers by pc
## sanity check for ensuring the rasters are in the correct projection
# print("Ensure that the projection of these rasters is WGS84:")
# print(paste0("Projection of envYr = ", projection(envYr)))
envDataClipped <- list()
for (n in 1:nlayers(envYr)) { # clip PCAs to study extent for given species
x <- envYr[[n]]
x <- crop(x, extent(studyRegionRasts[[n]]))
projection(x) <- getCRS("WGS84")
envDataClipped[[n]] <- x
}
envData <- stack(envDataClipped)
# plot(envData) # plot clipped environmental pca rasters
writeRaster(envData, fileName, format = 'GTiff', overwrite = T)
}
recordsFileName <- paste0('./species_records/03_',
gsub(' ', '_', tolower(sp)),
'_final_records.rData')
load(recordsFileName) # load records for given species
## prepare occurrence data for maxent ##
records <- data.frame(speciesSf_final)
records$geometry <- gsub("[c()]", "", records$geometry) # clean ll format in geometry column
# create separate columns for lat & long
records <- separate(data = records,
col = 'geometry',
into = ll,
sep = "\\,")
records$longitude <- as.double(records$longitude)
records$latitude <- as.double(records$latitude)
# extract environmental data at each occurrence point
occsEnv <- raster::extract(envData,
cbind(records$longitude,
records$latitude))
occsEnvDf <- as.data.frame(occsEnv) # convert to dataframe
records <- cbind(records, occsEnvDf) # add to records dataframe
## remove any records that fall in the water ##
if (exists('water')) rm(water) # remove 'water' from previous species
if (any(is.na(rowSums(occsEnvDf)))) { # define points in the water
water <- records[which(is.na(rowSums(occsEnvDf))), ]
water <- SpatialPointsDataFrame(water[,ll], data = water,
proj4 = getCRS('wgs84', TRUE))
}
if (any(is.na(rowSums(occsEnvDf)))) records <- records[-which(is.na(rowSums(occsEnvDf))), ] # remove records in water
# convert to sp object for visualization
recordsSp <- SpatialPointsDataFrame(records[, ll], data = records,
proj4 = getCRS('wgs84', TRUE))
# visualize points that fall in the water (colored in blue)
plot(recordsSp, pch = 16, cex = 0.5, col = "red",
main = paste0(sp, ' occurrences (BIEN) thinned'))
if (exists("water")) {
plot(water, col = 'blue', add = TRUE)
}
map("state", add = TRUE)
map("world", add = TRUE)
# save.image(paste0('./workspaces/04 - Modeling Workspace - Clipping ',
#                   sp, '_PC_', pc, '_GCM_', gcm))
bufferFileName <- paste0('./species_records/buffer/',
gsub(' ', '_', tolower(sp)),
'_buffer.rData')
load(bufferFileName)
## calculate calibration region at 320-km to extract bg sites from ##
# draw from all of NA #
calibBuffer <- st_buffer(st_transform(st_as_sf(x = recordsSp), getCRS('albersNA')),
dist = as_units(320, 'km'))
calibBuffer <- st_union(calibBuffer) # unionize
# convert to different crs objects
calibRegionSpAlb <- sp::spTransform(as(calibBuffer, 'Spatial'), getCRS('albersNA', TRUE))
calibRegionSpWgs <- sp::spTransform(calibRegionSpAlb, getCRS('wgs84', TRUE))
# set constants for retrieving background sites #
bgFileName <- './background_sites/Random Background Sites across Study Region.Rdata'
# load bg sites in calibration region if they have already been defined (bgTestSp, bgCalib, bgEnv, bg)
if (file.exists(bgFileName)) load(bgFileName) else {
# otherwise, get 20,000 random background sites from calibration region
bgTestSpAlb <- suppressWarnings(sp::spsample(calibRegionSpAlb, n=20000,
type='random', iter = 10))
bgTestSp <- sp::spTransform(bgTestSpAlb, wgs84_crs) # transform to wgs84
bgCalib <- as.data.frame(coordinates(bgTestSp)) # lat/long of background sites
names(bgCalib) <- ll
save(bgTestSp, bgCalib, file = bgFileName, compress = T, overwrite = T)
}
# plot the bg sites to verify
plot(bgTestSp, pch = 16, cex = 0.5, col = "red",
main = paste0(sp, ' background sites'))
plot(calibRegionSpWgs, add = TRUE, border = 'blue')
map("state", add = TRUE)
map("world", add = TRUE)
climate <- envData
bgEnv <- raster::extract(climate, bgCalib) # extract environment at random background sites
bgEnv <- as.data.frame(bgEnv) # convert to dataframe
# remove any sites with NA for at least one variable #
isNa <- is.na(rowSums(bgEnv))
if (any(isNa)) {
bgCalib <- bgCalib[-which(isNa), ]
bgEnv <- bgEnv[-which(isNa), ]
}
bg <- cbind(bgCalib, bgEnv) # combine with coordinates
names(bg)[1:2] <- ll # rename lat/long columns, respectively
presBg <- c(rep(1, nrow(records)), rep(0, nrow(bg))) # identify presences
occsEnv <- occsEnv[complete.cases(occsEnv), ] # remove NA values
## prepare env data frame for maxent ##
env <- rbind(occsEnv, bgEnv)
env <- cbind(presBg, env)
env <- as.data.frame(env)
env <- env[complete.cases(env), ] # remove NA values
## run maxent for species ##
# model tuning for easy fine-tuning later
envModel_tune <- enmSdm::trainMaxNet(data = env, resp = 'presBg',
classes = 'lpq', out = c('models', 'tuning'))
envModel <- envModel_tune$models[[1]] # select best fitted model
predictors <- c(paste0('pca', 1:pc))
# prediction for given year
envMap <- predict(
climate[[predictors]],
envModel,
filename = paste0('./models/predictions/', speciesAb_, '/GCM_', gcm,
'_PC', pc, '_', climYear, 'ybp'),
clamp = F,
format='GTiff',
overwrite = T,
type='cloglog')
envMapSp <- rasterToPolygons(envMap) # convert to spatial object for plotting
plot(rangeMap, border = 'blue', main = paste0('Maxent output, ', sp,
' occurrences'))
plot(envMap, add = TRUE)
plot(rangeMap, border = 'blue', add = TRUE)
map("state", add = TRUE)
map("world", add = TRUE)
points(records$longitude, records$latitude, pch = 16, cex = 0.6, col = 'red')
plot(envMap, main = paste0('Maxent output, ',
sp,
' occurrences'))
plot(rangeMap, border = 'blue', add = TRUE)
modelFileName <- paste0('./models/', speciesAb_, '_Maxent_PC',
pc, '_GCM_', gcm, '.Rdata')
save(envModel, file = modelFileName, compress = T, overwrite = T) # save model
outputFileName <- paste0('./models/predictions/', speciesAb_,
'/GCM_', gcm, '_PC', pc, '.rData')
save(rangeMap, envMap, envModel, records, file = outputFileName, overwrite = T)
}
sink()
sink('./ENM_script.txt')
for (gcm in gcmList) {
cat(paste0('\nGCM = ', gcm, ', Species: ', sp, '\n'))
# identify study region
studyRegionFileName <- '/Volumes/lj_mac_22/pollen/predictions-FRAXINUS_meanpred_iceMask.tif'
studyRegionRasts <- brick(studyRegionFileName)
# load climate for given gcm
load(paste0('/Volumes/lj_mac_22/MOBOT/by_genus/env_data/', gcm,
'/PCA_climate_rasters_pc', pc, '.Rdata'))
load(paste0('/Volumes/lj_mac_22/MOBOT/by_genus/env_data/', gcm,
'/PCA_prcomp_pc', pc, '.Rdata'))
# set constants for given gcm
fileName <- paste0('/Volumes/lj_mac_22/MOBOT/by_genus/env_data/', gcm,
'/clipped_data/envDataClipped_', climYear, 'YBP_pc', pc, '.tif')
vars <- names(clim[[1]])
# set constants for Lorenz gcm's
if (gcm == 'ccsm' | gcm == 'ecbilt') {
clim <- lorenz
workingFolder <- paste0('/Volumes/lj_mac_22/MOBOT/by_genus/env_data/', gcm,
'/tifs/', climYear, 'BP')
vars <- names(clim[[1]])
}
## load environment data from PCA ##
if (file.exists(fileName)) {  # if already clipped to respective year, load that
envData <- brick(fileName)
names(envData) <- paste0('pca', 1:pc) # rename raster layers to match pc
} else { # otherwise, clip data to correct climate year
pcPrediction <- list()
for (i in 1:length(clim)) { # label each env layer by variable name and year
names(clim[[i]]) <- vars
pcPrediction[i] <- raster::predict(clim[[i]], pca, index = 1:pc)
names(pcPrediction[[i]]) <- paste0("pc", 1:pc, "_", (i-1)*1000, "KYBP")
}
envDataPca <- stack(pcPrediction)
envYr <- pcPrediction[[(climYear/1000) + 1]] # keep only the PCA rasters for given climate year
names(envYr) <- paste0('pca', 1:pc) # label layers by pc
## sanity check for ensuring the rasters are in the correct projection
# print("Ensure that the projection of these rasters is WGS84:")
# print(paste0("Projection of envYr = ", projection(envYr)))
envDataClipped <- list()
for (n in 1:nlayers(envYr)) { # clip PCAs to study extent for given species
x <- envYr[[n]]
x <- crop(x, extent(studyRegionRasts[[n]]))
projection(x) <- getCRS("WGS84")
envDataClipped[[n]] <- x
}
envData <- stack(envDataClipped)
# plot(envData) # plot clipped environmental pca rasters
writeRaster(envData, fileName, format = 'GTiff', overwrite = T)
}
recordsFileName <- paste0('./species_records/03_',
gsub(' ', '_', tolower(sp)),
'_final_records.rData')
load(recordsFileName) # load records for given species
## prepare occurrence data for maxent ##
records <- data.frame(speciesSf_final)
records$geometry <- gsub("[c()]", "", records$geometry) # clean ll format in geometry column
# create separate columns for lat & long
records <- separate(data = records,
col = 'geometry',
into = ll,
sep = "\\,")
records$longitude <- as.double(records$longitude)
records$latitude <- as.double(records$latitude)
# extract environmental data at each occurrence point
occsEnv <- raster::extract(envData,
cbind(records$longitude,
records$latitude))
occsEnvDf <- as.data.frame(occsEnv) # convert to dataframe
records <- cbind(records, occsEnvDf) # add to records dataframe
## remove any records that fall in the water ##
if (exists('water')) rm(water) # remove 'water' from previous species
if (any(is.na(rowSums(occsEnvDf)))) { # define points in the water
water <- records[which(is.na(rowSums(occsEnvDf))), ]
water <- SpatialPointsDataFrame(water[,ll], data = water,
proj4 = getCRS('wgs84', TRUE))
}
if (any(is.na(rowSums(occsEnvDf)))) records <- records[-which(is.na(rowSums(occsEnvDf))), ] # remove records in water
# convert to sp object for visualization
recordsSp <- SpatialPointsDataFrame(records[, ll], data = records,
proj4 = getCRS('wgs84', TRUE))
# visualize points that fall in the water (colored in blue)
plot(recordsSp, pch = 16, cex = 0.5, col = "red",
main = paste0(sp, ' occurrences (BIEN) thinned'))
if (exists("water")) {
plot(water, col = 'blue', add = TRUE)
}
map("state", add = TRUE)
map("world", add = TRUE)
# save.image(paste0('./workspaces/04 - Modeling Workspace - Clipping ',
#                   sp, '_PC_', pc, '_GCM_', gcm))
bufferFileName <- paste0('./species_records/buffer/',
gsub(' ', '_', tolower(sp)),
'_buffer.rData')
load(bufferFileName)
## calculate calibration region at 320-km to extract bg sites from ##
# draw from all of NA #
calibBuffer <- st_buffer(st_transform(st_as_sf(x = recordsSp), getCRS('albersNA')),
dist = as_units(320, 'km'))
calibBuffer <- st_union(calibBuffer) # unionize
# convert to different crs objects
calibRegionSpAlb <- sp::spTransform(as(calibBuffer, 'Spatial'), getCRS('albersNA', TRUE))
calibRegionSpWgs <- sp::spTransform(calibRegionSpAlb, getCRS('wgs84', TRUE))
# set constants for retrieving background sites #
bgFileName <- './background_sites/Random Background Sites across Study Region.Rdata'
# load bg sites in calibration region if they have already been defined (bgTestSp, bgCalib, bgEnv, bg)
if (file.exists(bgFileName)) load(bgFileName) else {
# otherwise, get 20,000 random background sites from calibration region
bgTestSpAlb <- suppressWarnings(sp::spsample(calibRegionSpAlb, n=20000,
type='random', iter = 10))
bgTestSp <- sp::spTransform(bgTestSpAlb, wgs84_crs) # transform to wgs84
bgCalib <- as.data.frame(coordinates(bgTestSp)) # lat/long of background sites
names(bgCalib) <- ll
save(bgTestSp, bgCalib, file = bgFileName, compress = T, overwrite = T)
}
# plot the bg sites to verify
plot(bgTestSp, pch = 16, cex = 0.5, col = "red",
main = paste0(sp, ' background sites'))
plot(calibRegionSpWgs, add = TRUE, border = 'blue')
map("state", add = TRUE)
map("world", add = TRUE)
climate <- envData
bgEnv <- raster::extract(climate, bgCalib) # extract environment at random background sites
bgEnv <- as.data.frame(bgEnv) # convert to dataframe
# remove any sites with NA for at least one variable #
isNa <- is.na(rowSums(bgEnv))
if (any(isNa)) {
bgCalib <- bgCalib[-which(isNa), ]
bgEnv <- bgEnv[-which(isNa), ]
}
bg <- cbind(bgCalib, bgEnv) # combine with coordinates
names(bg)[1:2] <- ll # rename lat/long columns, respectively
presBg <- c(rep(1, nrow(records)), rep(0, nrow(bg))) # identify presences
occsEnv <- occsEnv[complete.cases(occsEnv), ] # remove NA values
## prepare env data frame for maxent ##
env <- rbind(occsEnv, bgEnv)
env <- cbind(presBg, env)
env <- as.data.frame(env)
env <- env[complete.cases(env), ] # remove NA values
## run maxent for species ##
# model tuning for easy fine-tuning later
envModel_tune <- enmSdm::trainMaxNet(data = env, resp = 'presBg',
classes = 'lpq', out = c('models', 'tuning'))
envModel <- envModel_tune$models[[1]] # select best fitted model
predictors <- c(paste0('pca', 1:pc))
# prediction for given year
envMap <- predict(
climate[[predictors]],
envModel,
filename = paste0('./models/predictions/', speciesAb_, '/GCM_', gcm,
'_PC', pc, '_', climYear, 'ybp'),
clamp = F,
format='GTiff',
overwrite = T,
type='cloglog')
envMapSp <- rasterToPolygons(envMap) # convert to spatial object for plotting
plot(rangeMap, border = 'blue', main = paste0('Maxent output, ', sp,
' occurrences'))
plot(envMap, add = TRUE)
plot(rangeMap, border = 'blue', add = TRUE)
map("state", add = TRUE)
map("world", add = TRUE)
points(records$longitude, records$latitude, pch = 16, cex = 0.6, col = 'red')
plot(envMap, main = paste0('Maxent output, ',
sp,
' occurrences'))
plot(rangeMap, border = 'blue', add = TRUE)
modelFileName <- paste0('./models/', speciesAb_, '_Maxent_PC',
pc, '_GCM_', gcm, '.Rdata')
save(envModel, file = modelFileName, compress = T, overwrite = T) # save model
outputFileName <- paste0('./models/predictions/', speciesAb_,
'/GCM_', gcm, '_PC', pc, '.rData')
save(rangeMap, envMap, envModel, records, file = outputFileName, overwrite = T)
}
sink()
sink('./ENM_script.txt')
for (gcm in gcmList) {
cat(paste0('\nGCM = ', gcm, ', Species: ', sp, '\n'))
# identify study region
studyRegionFileName <- '/Volumes/lj_mac_22/pollen/predictions-FRAXINUS_meanpred_iceMask.tif'
studyRegionRasts <- brick(studyRegionFileName)
# load climate for given gcm
load(paste0('/Volumes/lj_mac_22/MOBOT/by_genus/env_data/', gcm,
'/PCA_climate_rasters_pc', pc, '.Rdata'))
load(paste0('/Volumes/lj_mac_22/MOBOT/by_genus/env_data/', gcm,
'/PCA_prcomp_pc', pc, '.Rdata'))
# set constants for given gcm
fileName <- paste0('/Volumes/lj_mac_22/MOBOT/by_genus/env_data/', gcm,
'/clipped_data/envDataClipped_', climYear, 'YBP_pc', pc, '.tif')
vars <- names(clim[[1]])
# set constants for Lorenz gcm's
if (gcm == 'ccsm' | gcm == 'ecbilt') {
clim <- lorenz
workingFolder <- paste0('/Volumes/lj_mac_22/MOBOT/by_genus/env_data/', gcm,
'/tifs/', climYear, 'BP')
vars <- names(clim[[1]])
}
## load environment data from PCA ##
if (file.exists(fileName)) {  # if already clipped to respective year, load that
envData <- brick(fileName)
names(envData) <- paste0('pca', 1:pc) # rename raster layers to match pc
} else { # otherwise, clip data to correct climate year
pcPrediction <- list()
for (i in 1:length(clim)) { # label each env layer by variable name and year
names(clim[[i]]) <- vars
pcPrediction[i] <- raster::predict(clim[[i]], pca, index = 1:pc)
names(pcPrediction[[i]]) <- paste0("pc", 1:pc, "_", (i-1)*1000, "KYBP")
}
envDataPca <- stack(pcPrediction)
envYr <- pcPrediction[[(climYear/1000) + 1]] # keep only the PCA rasters for given climate year
names(envYr) <- paste0('pca', 1:pc) # label layers by pc
## sanity check for ensuring the rasters are in the correct projection
# print("Ensure that the projection of these rasters is WGS84:")
# print(paste0("Projection of envYr = ", projection(envYr)))
envDataClipped <- list()
for (n in 1:nlayers(envYr)) { # clip PCAs to study extent for given species
x <- envYr[[n]]
x <- crop(x, extent(studyRegionRasts[[n]]))
projection(x) <- getCRS("WGS84")
envDataClipped[[n]] <- x
}
envData <- stack(envDataClipped)
# plot(envData) # plot clipped environmental pca rasters
writeRaster(envData, fileName, format = 'GTiff', overwrite = T)
}
recordsFileName <- paste0('./species_records/03_',
gsub(' ', '_', tolower(sp)),
'_final_records.rData')
load(recordsFileName) # load records for given species
## prepare occurrence data for maxent ##
records <- data.frame(speciesSf_final)
records$geometry <- gsub("[c()]", "", records$geometry) # clean ll format in geometry column
# create separate columns for lat & long
records <- separate(data = records,
col = 'geometry',
into = ll,
sep = "\\,")
records$longitude <- as.double(records$longitude)
records$latitude <- as.double(records$latitude)
# extract environmental data at each occurrence point
occsEnv <- raster::extract(envData,
cbind(records$longitude,
records$latitude))
occsEnvDf <- as.data.frame(occsEnv) # convert to dataframe
records <- cbind(records, occsEnvDf) # add to records dataframe
## remove any records that fall in the water ##
if (exists('water')) rm(water) # remove 'water' from previous species
if (any(is.na(rowSums(occsEnvDf)))) { # define points in the water
water <- records[which(is.na(rowSums(occsEnvDf))), ]
water <- SpatialPointsDataFrame(water[,ll], data = water,
proj4 = getCRS('wgs84', TRUE))
}
if (any(is.na(rowSums(occsEnvDf)))) records <- records[-which(is.na(rowSums(occsEnvDf))), ] # remove records in water
# convert to sp object for visualization
recordsSp <- SpatialPointsDataFrame(records[, ll], data = records,
proj4 = getCRS('wgs84', TRUE))
# visualize points that fall in the water (colored in blue)
plot(recordsSp, pch = 16, cex = 0.5, col = "red",
main = paste0(sp, ' occurrences (BIEN) thinned'))
if (exists("water")) {
plot(water, col = 'blue', add = TRUE)
}
map("state", add = TRUE)
map("world", add = TRUE)
# save.image(paste0('./workspaces/04 - Modeling Workspace - Clipping ',
#                   sp, '_PC_', pc, '_GCM_', gcm))
bufferFileName <- paste0('./species_records/buffer/',
gsub(' ', '_', tolower(sp)),
'_buffer.rData')
load(bufferFileName)
## calculate calibration region at 320-km to extract bg sites from ##
# draw from all of NA #
calibBuffer <- st_buffer(st_transform(st_as_sf(x = recordsSp), getCRS('albersNA')),
dist = as_units(320, 'km'))
calibBuffer <- st_union(calibBuffer) # unionize
# convert to different crs objects
calibRegionSpAlb <- sp::spTransform(as(calibBuffer, 'Spatial'), getCRS('albersNA', TRUE))
calibRegionSpWgs <- sp::spTransform(calibRegionSpAlb, getCRS('wgs84', TRUE))
# set constants for retrieving background sites #
bgFileName <- './background_sites/Random Background Sites across Study Region.Rdata'
# load bg sites in calibration region if they have already been defined (bgTestSp, bgCalib, bgEnv, bg)
if (file.exists(bgFileName)) load(bgFileName) else {
# otherwise, get 20,000 random background sites from calibration region
bgTestSpAlb <- suppressWarnings(sp::spsample(calibRegionSpAlb, n=20000,
type='random', iter = 10))
bgTestSp <- sp::spTransform(bgTestSpAlb, wgs84_crs) # transform to wgs84
bgCalib <- as.data.frame(coordinates(bgTestSp)) # lat/long of background sites
names(bgCalib) <- ll
save(bgTestSp, bgCalib, file = bgFileName, compress = T, overwrite = T)
}
# plot the bg sites to verify
plot(bgTestSp, pch = 16, cex = 0.5, col = "red",
main = paste0(sp, ' background sites'))
plot(calibRegionSpWgs, add = TRUE, border = 'blue')
map("state", add = TRUE)
map("world", add = TRUE)
climate <- envData
bgEnv <- raster::extract(climate, bgCalib) # extract environment at random background sites
bgEnv <- as.data.frame(bgEnv) # convert to dataframe
# remove any sites with NA for at least one variable #
isNa <- is.na(rowSums(bgEnv))
if (any(isNa)) {
bgCalib <- bgCalib[-which(isNa), ]
bgEnv <- bgEnv[-which(isNa), ]
}
bg <- cbind(bgCalib, bgEnv) # combine with coordinates
names(bg)[1:2] <- ll # rename lat/long columns, respectively
presBg <- c(rep(1, nrow(records)), rep(0, nrow(bg))) # identify presences
occsEnv <- occsEnv[complete.cases(occsEnv), ] # remove NA values
## prepare env data frame for maxent ##
env <- rbind(occsEnv, bgEnv)
env <- cbind(presBg, env)
env <- as.data.frame(env)
env <- env[complete.cases(env), ] # remove NA values
## run maxent for species ##
# model tuning for easy fine-tuning later
envModel_tune <- enmSdm::trainMaxNet(data = env, resp = 'presBg',
classes = 'lpq', out = c('models', 'tuning'))
envModel <- envModel_tune$models[[1]] # select best fitted model
predictors <- c(paste0('pca', 1:pc))
# prediction for given year
envMap <- predict(
climate[[predictors]],
envModel,
filename = paste0('./models/predictions/', speciesAb_, '/GCM_', gcm,
'_PC', pc, '_', climYear, 'ybp'),
clamp = F,
format='GTiff',
overwrite = T,
type='cloglog')
envMapSp <- rasterToPolygons(envMap) # convert to spatial object for plotting
plot(range, border = 'blue', main = paste0('Maxent output, ', sp,
' occurrences'))
plot(envMap, add = TRUE)
plot(range, border = 'blue', add = TRUE)
map("state", add = TRUE)
map("world", add = TRUE)
points(records$longitude, records$latitude, pch = 16, cex = 0.6, col = 'red')
plot(envMap, main = paste0('Maxent output, ',
sp,
' occurrences'))
plot(range, border = 'blue', add = TRUE)
modelFileName <- paste0('./models/', speciesAb_, '_Maxent_PC',
pc, '_GCM_', gcm, '.Rdata')
save(envModel, file = modelFileName, compress = T, overwrite = T) # save model
outputFileName <- paste0('./models/predictions/', speciesAb_,
'/GCM_', gcm, '_PC', pc, '.rData')
save(range, envMap, envModel, records, file = outputFileName, overwrite = T)
}
sink()
